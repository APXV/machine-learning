{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação\n",
    "\n",
    "## SVM (Support Vector Machine)\n",
    "\n",
    "O SVM é um classificador discriminativo formalmente definido por um hiperplano de separação. Em outras palavras, dado um conjunto de dados de treinamento classificados (aprendizado supervisionado), o algoritmo gera um hiperplano ideal que categoriza novos exemplos. No espaço bidimensional, esse hiperplano é uma linha que divide um plano em duas partes, onde cada classe fica em cada lado.\n",
    "\n",
    "<img src=\"figures/svm.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o classificador, utilizaremos o caso contido no arquivo ```exemplo2.csv```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>conta_corrente</th>\n",
       "      <th>risco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.257389</td>\n",
       "      <td>783.127911</td>\n",
       "      <td>ruim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21.766573</td>\n",
       "      <td>979.747521</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25.321033</td>\n",
       "      <td>1065.328054</td>\n",
       "      <td>ruim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23.919268</td>\n",
       "      <td>1195.758078</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21.805298</td>\n",
       "      <td>1083.764450</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idade  conta_corrente risco\n",
       "0  21.257389      783.127911  ruim\n",
       "1  21.766573      979.747521   bom\n",
       "2  25.321033     1065.328054  ruim\n",
       "3  23.919268     1195.758078   bom\n",
       "4  21.805298     1083.764450   bom"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('dados/exemplo2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o classificador SVM\n",
    "O classificador SVM está presente no pacote ```sklearn``` no caminho ```sklearn.svm``` e é identificado como ```SVC```. O bloco de código abaixo, faremos o processo completo de teste do classifidar. Dessa forma, faremos a importação da função ```train_test_split``` presente no subpacote ```sklearn.model_selection```, da função ```MinMaxScaler``` do subpacote ```sklearn.preprocessing``` e da função ```accuracy_score``` presente no subpacote ```sklearn.metrics```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8381294964028777"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separação dos inputs e outputs\n",
    "X = df.drop('risco', axis=1)\n",
    "y = df.risco\n",
    "\n",
    "# Normalização dos inputs\n",
    "normalizador = MinMaxScaler()\n",
    "X_norm = normalizador.fit_transform(X)\n",
    "\n",
    "# Divisão dos conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=1/3, random_state=42)\n",
    "\n",
    "# Treinamento do classificador SVM\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Cálculo da precisão\n",
    "accuracy_score(y_test, svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos a precisão de 0.8381 (inferior ao obtido pelo KNN)\n",
    "### Trabalhando com _inputs_ categóricos\n",
    "Aplicaremos o classificador em um novo conjunto de dados presente no arquivo ```exemplo3.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>conta_corrente</th>\n",
       "      <th>sexo</th>\n",
       "      <th>risco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.257389</td>\n",
       "      <td>783.127911</td>\n",
       "      <td>masculino</td>\n",
       "      <td>ruim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21.766573</td>\n",
       "      <td>979.747521</td>\n",
       "      <td>feminino</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25.321033</td>\n",
       "      <td>1065.328054</td>\n",
       "      <td>feminino</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23.919268</td>\n",
       "      <td>1195.758078</td>\n",
       "      <td>feminino</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21.805298</td>\n",
       "      <td>1083.764450</td>\n",
       "      <td>feminino</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idade  conta_corrente       sexo risco\n",
       "0  21.257389      783.127911  masculino  ruim\n",
       "1  21.766573      979.747521   feminino   bom\n",
       "2  25.321033     1065.328054   feminino   bom\n",
       "3  23.919268     1195.758078   feminino   bom\n",
       "4  21.805298     1083.764450   feminino   bom"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('dados/exemplo3.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo temos a coluna ```sexo``` identificando o sexo de cada cliente como ```masculino``` ou ```feminino```. As variáveis de _input_ de um classificador devem, necessariamente, ser do tipo numérico.\n",
    "\n",
    "Para transformar as informações contidas na coluna ```sexo``` para o formato numérico, faremos a binarização da coluna através da classe ```OneHotEncoder```. \n",
    "\n",
    "Primeiro, faremos a seleção das variáveis de _input_ do tipo ```object``` utilizando o comando ```DataFrame.select_dtypes()```, passando para o parâmetro ```include``` a lista de tipos selecionados (nesse caso, o tipo ```object```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>masculino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>feminino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>feminino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>feminino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>feminino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sexo\n",
       "0  masculino\n",
       "1   feminino\n",
       "2   feminino\n",
       "3   feminino\n",
       "4   feminino"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2.drop('risco', axis=1)\n",
    "y = df2.risco\n",
    "\n",
    "X.select_dtypes(include=['object']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado é um ```DataFrame``` contendo somente a coluna ```sexo```.\n",
    "\n",
    "Faremos a binarização desse ```DataFrame``` utilizando a classe ```OneHotEncoder``` presente no subpacote ```sklearn.preprocessing```. Chamaremos de ```onehot``` o objeto da classe ```OneHotEncoder```, passando os parâmetros ```sparse=False``` (para que o resultado não seja gerado no formato de uma matriz esparsa) e ```drop=\"first\"``` (para eliminar redundância na binarização). \n",
    "\n",
    "Aplicaremos o operador utilizando o comando ```OneHotEncoder.fit_transform()```, atribuindo o resultado a uma variável chamada ```X_bin```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder(sparse=False, drop=\"first\")\n",
    "X_bin = onehot.fit_transform(X.select_dtypes(include=['object']))\n",
    "X_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faremos a normalização dos dados numéricos utilizando a classe ```MinMaxScaler```, criando um objeto dessa classe chamado ```mmscaler```. Esse operador recebe somente dados numéricos, fazendo-se necessária a seleção de colunas contendo somente dados desse tipo. Para tando, utilizaremos mais uma vez o comando ```DataFrame.select_dtypes()```. Mas, dessa vez, passaremos o parâmetro ```exclude=['object']```, excluindo todas as colunas do tipo ```object```. Chamaremos o ```array``` resultante de ```X_num```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05586473, 0.06720224],\n",
       "       [0.06499436, 0.09938945],\n",
       "       [0.12872564, 0.11339923],\n",
       "       ...,\n",
       "       [0.85424954, 0.36522222],\n",
       "       [0.62401886, 0.42781034],\n",
       "       [0.61473291, 0.54031447]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmscaler = MinMaxScaler()\n",
    "X_num = mmscaler.fit_transform(X.select_dtypes(exclude=['object']))\n",
    "X_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, uniremos os ```DataFrame``` ```X_bin``` e ```X_num``` em um só ```DataFrame``` chamado ```X_all```. Para tando, utilizaremos o comando ```numpy.append()``` presente no pacote ```numpy```. \n",
    "\n",
    "Faremos a importação do pacote dando a ele o apelido de ```np``` e aplicaremos a função ```append()```, passando como parâmetro os ```array``` ```X_num``` e ```X_bin```. O parâmetro ```axis=1``` precisa ser acrescentado à função para explicitar que a junção será feita no eixo das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05586473, 0.06720224, 1.        ],\n",
       "       [0.06499436, 0.09938945, 0.        ],\n",
       "       [0.12872564, 0.11339923, 0.        ],\n",
       "       ...,\n",
       "       [0.85424954, 0.36522222, 1.        ],\n",
       "       [0.62401886, 0.42781034, 1.        ],\n",
       "       [0.61473291, 0.54031447, 1.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_all = np.append(X_num, X_bin, axis=1)\n",
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos testar o classificador com o processo de validação abaixo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7146282973621103"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divisão dos conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=1/3, random_state=42)\n",
    "\n",
    "# Treinamento do classificador SVM\n",
    "svc2 = SVC()\n",
    "svc2.fit(X_train, y_train)\n",
    "\n",
    "# Cálculo da precisão\n",
    "accuracy_score(y_test, svc2.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar o classificar para prever a classe de um novo conjunto de dados, criaremos um ```DataFrame``` contendo cinco novos clientes com as seguintes informações:\n",
    "\n",
    "|idade|conta_corrente|sexo|\n",
    "|-|-|-|\n",
    "|20|800|masculino|\n",
    "|25|4000|feminino|\n",
    "|50|2200|masculino|\n",
    "|35|3200|feminino|\n",
    "|75|1000|masculino|\n",
    "\n",
    "Para isso, utilizaremos o comando ```pandas.DataFrame()```, passando como parâmetro o dicionário contendo como chave, os nomes das colunas e como valores, a lista de valores. Chamaremos o novo ```DataFrame```de ```df_new```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>conta_corrente</th>\n",
       "      <th>sexo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>800</td>\n",
       "      <td>masculino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4000</td>\n",
       "      <td>feminino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2200</td>\n",
       "      <td>masculino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>3200</td>\n",
       "      <td>feminino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>1000</td>\n",
       "      <td>feminino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idade  conta_corrente       sexo\n",
       "0     20             800  masculino\n",
       "1     25            4000   feminino\n",
       "2     50            2200  masculino\n",
       "3     35            3200   feminino\n",
       "4     75            1000   feminino"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame({'idade': [20, 25, 50, 35, 75], \n",
    "                      'conta_corrente': [800, 4000, 2200, 3200, 1000], \n",
    "                      'sexo': ['masculino', 'feminino', 'masculino', 'feminino', 'feminino']})\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a previsão do risco de cada um dos novos clientes, precisamos transformar o ```DataFrame``` para o mesmo formato utilizado no treinamento do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ruim', 'bom', 'ruim', 'bom', 'bom'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_bin = onehot.transform(df_new.select_dtypes(include=['object']))\n",
    "X_new_num = mmscaler.transform(df_new.select_dtypes(exclude=['object']))\n",
    "X_new = np.append(X_new_num, X_new_bin, axis=1)\n",
    "svc2.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mostrar o resultado no formato de um ```DataFrame```, basta criarmos uma nova coluna contendo os resultados da previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>conta_corrente</th>\n",
       "      <th>sexo</th>\n",
       "      <th>previsao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>800</td>\n",
       "      <td>masculino</td>\n",
       "      <td>ruim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4000</td>\n",
       "      <td>feminino</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2200</td>\n",
       "      <td>masculino</td>\n",
       "      <td>ruim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>3200</td>\n",
       "      <td>feminino</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>1000</td>\n",
       "      <td>feminino</td>\n",
       "      <td>bom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idade  conta_corrente       sexo previsao\n",
       "0     20             800  masculino     ruim\n",
       "1     25            4000   feminino      bom\n",
       "2     50            2200  masculino     ruim\n",
       "3     35            3200   feminino      bom\n",
       "4     75            1000   feminino      bom"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_previsao = df_new.copy()\n",
    "df_previsao['previsao'] = svc2.predict(X_new)\n",
    "df_previsao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floresta Aleatória\n",
    "\n",
    "A floresta aleatória, como o próprio nome indica, consiste em um grande número de árvores de decisão individuais que funcionam como um conjunto. Cada árvore individual na floresta aleatória gera uma previsão de classe e a classe com mais votos se torna a previsão do nosso modelo.\n",
    "\n",
    "O conceito fundamental por trás da floresta aleatória é simples, mas poderoso: a sabedoria das multidões. Na linguagem da ciência de dados, a razão pela qual o modelo funciona tão bem está associado ao fato de que um grande número de modelos (árvores) relativamente não correlacionados que operam como um comitê superará qualquer um dos modelos constituintes individuais.\n",
    "\n",
    "Para este modelo, o parâmetro mais básico a ser definido é o número de árvores presente na floresta. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249400479616307"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, rfc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados contidos no arquivo ```exemplo3.csv``` apresentam um exemplo semelhante ao anterior, onde neste considera-se também o sexo do cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'exemplo3.csv' does not exist: b'exemplo3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-dbeb6b05425e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exemplo3.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'exemplo3.csv' does not exist: b'exemplo3.csv'"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('exemplo3.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para coluna ```sexo```, faremos a transformação através da binarização de variáveis categóricas. Utilizando o comando ``` pd.get_dummies(Series, prefix='nome_do_prefixo')```, criaremos as colunas ```sexo_feminino``` e ```sexo_masculino```, onde o valor 1 representa o valor verdadeiro e 0 o falso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexo = pd.get_dummies(df2.sexo, prefix='sexo')\n",
    "sexo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para concatenar o dataframe ```sexo``` com ```df2```, utilizamos o comando ```pd.concat(lista_de_dataframes, axis=1)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df2, sexo], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicaremos o normalizador ```MinMaxScaler()``` para as colunas ```idade``` e ```conta_corrente```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler().fit(df[['idade', 'conta_corrente']])\n",
    "df2[['idade', 'conta_corrente']] = minmax.transform(df[['idade', 'conta_corrente']]) \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, aplicamos o treinamento e teste do classificador para verificar a acurácia do mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(['risco', 'sexo'], axis=1)\n",
    "y = df2.risco\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, rfc2.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo mostra a aplicação do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "idade = 22\n",
    "cc = 1200\n",
    "sexo = 'masculino'\n",
    "\n",
    "s = {'masculino': [0, 1], 'feminino': [1, 0]}\n",
    "values = np.append(minmax.transform([[idade, cc]])[0], s[sexo])\n",
    "rfc2.predict([values])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
